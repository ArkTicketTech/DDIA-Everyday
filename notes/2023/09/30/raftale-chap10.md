#### MapReduce工作流

单个MapReduce作业可以解决的问题范围有限，以日志分析为例，单个MapReduce作业可以确定每个URL的页面浏览次数，但无法确定最常见的URL，这需要第二轮排序。

所以需要一个作业的输出成为下一个作业的输入，第一个作业必须将其输出配置为HDFS的指定目录，第二个作业必须将其输入配置为同一个目录。从MapReduce来看，这是两个独立的作业。



为了处理这些作业之间的依赖关系，很多针对Hadoop的工作流调度被开发出来，包括Oozie、Azkaban、Luigi、Airflow 和 Pinball。



这些调度程序还具有管理功能，在维护大量批处理作业时非常有用。在构建推荐系统时，由50-100个MapReduce作业组成的工作流是常见的。而在大型组织中，许多不同的团队可能运行不同的作业来读取彼此的输出。工具支持对于管理这样复杂的数据流而言非常重要。Hadoop 的各种高级工具（如 Pig 、Hive、Cascading、Crunch和 FlumeJava）也能自动布线组装多个 MapReduce 阶段，生成合适的工作流。



### Reduce侧链接与分组



侧链接是指数据集中解析某种关联的全量存在，比如下图的事件日志，描述登录用户在网站上做的事情（称为活动事件，或点击流数据），右侧是用户数据表。




实现连接的最简单的方式是：逐个遍历活动事件，并为每个遇到的用户ID查询用户数据库（在远程服务上），但不足是性能会非常差：处理吞吐量受限于数据库服务器的往返时间。本地缓存的有效性很大程度上取决于数据的分布，并行运行大量查询可能会压垮数据库。



为了在批处理过程中实现良好的吞吐量，计算必须尽可能在单台机器上运行。更好的方法是获取用户数据库的副本，例如使用ETL进程是从数据库提取数据，并将它和用户日志放入同一分布式文件系统中。然后你可以将用户数据库存储在HDFS的一组文件中，而用户活动记录存储在另一组文件中，并能用MapReduce将所有相关记录集中到同一个地方进行高效处理



### Hadoop与分布式数据库的对比

Hadoop有点像Unix的分布式版本，其中HDFS是文件系统。

MapReduce并不新鲜，并行连接算法已经在大规模并行处理（MPP）数据库中实现。

最大的区别是：MPP数据库专注于在一组机器上并行执行分析SQL查询，而MapReduce和分布式文件系统的组合更像是一个可以运行任意程序的通用操作系统。



MapReduce针对频繁故障设计，适用于较大的作业，长时间的处理有很大概率遇到问题；

被设计为能够容忍频繁意外任务终止的原因：不是因为硬件很不可靠，而是因为任意终止进程的自由有利于提高计算集群中的资源利用率。



## MapReduce之后

将中间状态写入文件的过程为物化。



完全物化中间状态的不足：

1. 必须等前驱任务完成，整体工作流程效率低；
2. Mapper处理前驱代码有时是没有必要的；



新的分布式批处理的数据流引擎被开发出来，如Spark、Flink、 Tez。

它们有一个共同点：把整个工作流作为单个作业来处理，而不是把它分解为独立的子作业。



由于它们将工作流显式建模为数据从几个处理阶段穿过，所以这些系统被称为数据流引擎，像 MapReduce 一样，它们在一条线上通过反复调用用户定义的函数来一次处理一条记录，它们通过输入分区来并行化载荷，它们通过网络将一个函数的输出复制到另一个函数的输入。与 MapReduce 不同，这些函数不需要严格扮演交织的 Map 与 Reduce 的角色，而是可以以更灵活的方式进行组合。我们称这些函数为 算子（operators）。



与MapReduce相比，有以下优点：

1. 排序等昂贵的工作只需要在实际需要的地方执行，而不是默认在每个Map和Reduce之间出现；
2. 没有不必要的Map任务，因为Mapper所做的工作通常可以合并到前面的Reduce算子中；
3. 利用局部性进行优化
4. 算子间的中间状态足以保存在内存中或写入本地磁盘，比HDFS需要更好啊的IO
5. 算子可以在输入就绪后立刻开始执行，后续阶段无需等待前驱阶段整个完成后再开始
6. 减小启动开销，JVM进程可以重用来运行启动开销（MapReduce为每个任务启动一个新的JVM）



容错：

完全物化中间状态至分布式文件系统的一个优点是：它具有持久性，MapReduce的容错性相当容易。

Spark, Flink, Tez避免将中间状态写入HDFS，采用了不同的方法来容错，那就是从先前保存的状态重新开始计算。

## 本章小结

分布式批处理框架需要解决的两个主要问题是：

1. 分区：Mapper根据输入文件块进行分区，Mapper的输出被重新分区、排序并合并到可配置数量的Reducer分区中，这一过程的目的是把所有的相关数据都放到同一个地方。
2. 容错：MapReduce经常写入磁盘，这使得从单个失败的任务恢复很轻松，无需重新启动整个作业，但在无故障的情况下减慢了执行速度。数据流引擎更多地将中间状态保存在内存中，更少地物化中间状态，这意味着如果节点发生了故障，则需要重新计算更多的数据。确定性算子减少了需要重新计算的数据量。



分区算法：

1. 排序合并连接
2. 广播散列连接
3. 分区散列连接
