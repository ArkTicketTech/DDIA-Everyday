### 单对象和多对象操作

从关系型数据库的角度来看，单对象就是客户端的单个指令，比如更新一张表中id为1的数据；多对象是客户端同时想操作多个对象，比如想同时更新多张表。

数据库为单对象的写入提供了原子性和隔离性，原子性可以通过日志来实现崩溃恢复，隔离性可以使用单个对象的锁或者是CAS来实现。


原子性的保证让事情变得简单，避免了部分成功部分失败，当全部失败时客户端可以进行重试。

但重试也需要仔细评估，并不是所有的场景下重试都是对的：

1. 事务已经被成功提交，但返回给用户时出错，用户如果简单重试，就可能产生冗余数据；
2. 由于系统负载过高，造成事务执行失败，如果无脑重试，会进一步加重系统负担：可以使用指数后退方式重试，并且限制最大重试次数；
3. 临时性错误时（如死锁、异常情况、临时性网络中断和故障切换）后才值得重试，发生永久性错误后重试是没有意义的。
4. 如果事务在数据库之外也有副作用，如果想确保几个不同的系统一起提交或者放弃，需要考虑两阶段提交

## 弱隔离级别

并发的困难：

1. 并发bug很难通过测试找到，因为这样的错误只会在特殊的时序下才会触发，可能出现很少并且很难复现。
2. 并发性很难推理，特别是在大型应用中，很多代码都在同时访问数据库，并且用户也可能是并发的。

出于这些原因，数据库试图通过提供事务隔离来隐藏应用程序开发者的并发问题。从理论上来讲，隔离可以通过假装没有并发发生，最直接的是强隔离 加锁可串行化，但客户端或者是数据库 大部分时候 都不愿意使用可串行的隔离级别，因为他们认为可串行化有较大的性能损失。因此，在实际中，系统通常使用相对较弱的隔离级别来防止一部分的并发问题，但弱隔离级别并不好理解，使用不当会遇到一些微妙的错误。因此对于使用者来说，了解弱隔离级别成为必须。

隔离级别从小到大：

1. 读未提交；
2. 读已提交；
3. 可重复度；
4. 可串行化

### 读未提交

读未提交解决的是脏写问题，什么是脏写？

如果两个事务同时尝试更新数据库的相同对象，我们通常认为后面的写入会覆盖前面的写入。但是如果前面的写入尚未提交，后面的写入覆盖了这个尚未提交的写入，这看起来公平吗？

如果后面的写入先开始写，前面的写入后开始写，但是先开始写入由于某种原因延迟（长事务），导致了后开始写的事务的数据反而被先开始写的事务覆盖。

两种时序问题：

1. 后开始的事务写的数据覆盖先开始的事务写的数据：脏写
2. 先开始的事务写的数据覆盖了后开始的事务写的数据

也就是说，当两个事务同时更新数据库中的相同对象时，如果未提交的数据可以被其他事务覆盖，很明显会产生数据上的混乱。哪一个事务更有权力覆盖其他事务未提交的数据，很难讲的清楚。

当一个事务涉及到操作多个对象时，多个对象之间保持了一种约束（其实就是前面提到的一致性），当同时有两个事务操作相同的多个对象，情况就可能变得复杂。

每个对象最终以哪个事务ID的写入是随机的，最后可能表现为不同的对象采用了不同事务的写入，业务上产生了极大的混淆。

比如：

1. 以一个二手车销售网站为例，Alice 和 Bob 两个人同时试图购买同一辆车。购买汽车需要两次数据库写入：网站上的商品列表需要更新，以反映买家的购买，销售发票需要发送给买家。在下图的情况下，销售是属于 Bob 的（因为他成功更新了商品列表），但发票却寄送给了 Alice（因为她成功更新了发票表）
2. 或者表现为销售属于Alice，但发票寄给了Bob。

![](http://ddia.vonng.com/img/fig7-5.png)


读未提交解决了脏写问题，保证了写入数据库时，只会覆盖已提交的数据（no dirty writes）


#### 脏写的解决手段

避免脏写，一般的做法是延迟第二次写入，直到第一次写入事务提交或中止。

最常见的情况是，数据库通过行锁来防止脏写，当事务想修改特定对象（行、文档）时，它必须首先获得该对象的锁。一次只有一个事务可以持有任何给定对象的锁，如果另一个事务要写入同一个对象，则必须等到第一个事务提交或中止后，才能获取该锁并继续。


但读未提交没有解决脏读的问题。

### 读已提交

读已提交主要解决的是脏读问题，脏读指的是一个事务看到了另一个事务尚未提交的数据。在业务上的危害表现为

1. 事务操作多对象时，用户看到的可能是部分对象来自于操作前的状态，部分对象来自于操作时/后的状态。比如账户A（余额500）向账户B（余额500）转100，用户看到了扣款后的账户A有余额400，同时看到了加款前的账户B余额500，用户会以为转账失败，看到自己的账户少了100，直到事务提交后他再次刷新。

1. 1. 这里面的问题是，用户读到了未提交事务的账户A的数据，账户A的数据是操作后的状态，但账户B的数据确实操作前的状态。

1. 第二个危害是，事务中止，所有写入都会回滚，如果数据库允许脏读，用户会时常看到稍后需要回滚的数据，仔细思考后果更严重。


读已提交保证解决脏读和脏写问题。

#### 脏读的解决手段

如何防止脏读：

1. 一种思路是 等待上面的写锁释放后才能读取，这能确保未提交的值不会发生读取。但一个长时间运行的写入事务会迫使只读事务陷入长时间等待，不利于操作。甚至可能由于部分的延迟造成连锁反应，导致其他部分出问题。

1. 1. 相当于是写阻塞了读；

因此大多数数据库的思路是：对于写入的每个对象，数据库只会记住旧的已提交值，和由当前持有写入锁的事务设置的新值。当事务正在进行时，任何其他读取对象的事务都会拿到旧值，只有当新值提交后，事务才会切换到读取新值。

### 可重复读

![img](https://cdn.nlark.com/yuque/0/2023/png/32473878/1691673209367-fca7a518-ac8c-41fb-82b1-dca768b6016c.png)

上面没有读取未提交的事务结果（无脏读），也没有并发写入造成的脏写（无脏写），开启了一个事务，先后读取了两次，但两次的读取结果却不一致，Alice先是看到账户1有500，再是看到账户2有400，总额计算是900，Alice肯定会感到困惑，但实际上她的钱并没有少，稍后重新刷新就好了。

这种异常被称为不可重复读（nonrepeatable read）或读取偏差（read skew），如果Alice在事务结束后再次读取账户1的余额，她将看到600。

如果能容忍这种不可重复读，那读已提交的隔离级别就够了，但有些场景，不能容忍这种暂时的不一致。

1. 备份：进行备份需要复制整个数据库，备份进程进行时，数据库仍然会接受写入操作，因此备份可能会包含一些旧的部分和一些新的部分。如果从这样的备份中恢复，那么不一致（消失的钱）就会变成永久的。

1. 1. 备份不是根据预写日志的吗？有点怀疑这个例子

1. 分析查询和完整性检查：有时，你可能需要运行一个查询，扫描大部分的数据库，如果这些查询在不同时间点观测数据库的不同部分，则可能返回毫无意义的结果

快照隔离是不可重复读最常见的解决方案，每个事务都从数据库的一致快照（consistent snapshot）中读取，也就是说，事务可以看到事务开始时在数据库中提交的所有数据，即使这些事务随后被另一个事务更改，每个事务也只能看到特定时间点的旧数据。

#### 不可重复读的解决手段

同样是写锁防止脏写。

实现快照隔离的手段是 多版本并发控制**（MVCC, multi-version concurrency control）：**

**当一个事务开始时，它被赋予一个唯一的，永远增长的事务ID，每当事务向数据库写入任何内容时，它所写入的数据都会被标记上写入者的事务ID。**

**![](**[**http://ddia.vonng.com/img/fig7-7.png**](http://ddia.vonng.com/img/fig7-7.png)**)**

**表中的每一行数据会被赋予**`**created_by**`**和**`**deleted_by**`**字段，created_by记录事务ID，**`**deleted_by**`**有值就表示有新的事务ID修改了数据。每次查看快照时，如果created_by大于当前的事务ID，说明该行被修改过，那还是读取小于等于当前事务ID的快照来避免不可重复读。**
