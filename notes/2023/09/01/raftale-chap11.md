#### 确认与重新传递

消费者可能会崩溃，所有一种解决方法是：代理向消费者发送消息，但消费者没有处理或者是消费者崩溃之前只进行了部分处理。为了确保消息不会丢失，消息代理使用「确认」：客户端必须显式告知代理消息处理完毕的时间，以便代理能够将消息从队列中移除。



但确认还有一个失败的原因是：消费者处理完毕了，返回确认消息时却因为网络堵塞超时了，代理超出一段时间未收到确认，代理则认为消息没有被处理，因此它将消息再递送给另一个消费者。



这会导致一个问题：如果第一次消息消费成功，那可能会进行第二次消费，如果执行任务没有幂等，将带来副作用；如果消息消费失败，那消息的消费顺序也有可能被打乱，如果消息之间有因果关系，那就会有新的问题。



### 分区日志

大多数消息代理在消息成功传递给消费者时会自动删除消息，因为他们认为由于它们的工作集很小，如果代理需要缓冲很多消息，比如因为消费者速度较慢，导致内存消息膨胀，可能会溢出到磁盘，整体吞吐量会恶化。

这种思想被封装在JMS/AMQP的标准中，并且被RabbitMQ\ActiveMQ等所实现。

AMQP/JMS风格的消息传递，收到消息是具有破坏性的，因为确认可能导致消息从代理中被删除，因此你不能期望再次运行同一个消费者能得到相同的结果。

如果你将新的消费者添加到消息代理系统，通常只能接受到消费者注册后开始发送的消息。但如果你希望随时为文件和数据库添加新的客户端，且能读取任意久远的数据，何不利用数据库和文件系统会永久记录的特点，再结合消息传递的低延时通知，这就基于日志的消息代理背后的思想：

1. 结合数据库的优势：持久存储
2. 具有消息传递的特点：低延迟通知



#### 使用日志进行消息存储

日志只是磁盘上简单的仅追加记录序列。

生产者通过将消息追加到日志末尾来发送消息。而消费者通过依次读取日志来接受消息，如果消费者读到日志末尾，则会等待新消息追加到通知。Unix工具`tail -f`能监视文件被追加写入到数据，基本就是这样工作的。

为了伸缩超出单个磁盘所能提供的高吞吐量，可以对日志进行分区。一个主题可以定义为一组携带相同类型消息的分区。

在每个分区内，代理为每个消息分配一个单调递增的偏移量（offset），因为分区是仅追加写入的，分区内的消息是完全有序的。但不同分区的消息则不能保证顺序，所有如果你需要顺序的特性，那就需要写入同一个分区。



Kafka就是基于日志的消息代理。尽管这些消息代理将所有消息写入磁盘，但通过跨多台机器分区，每秒能够实现数百万条消息的吞吐量，并通过复制来实现容错性。



#### 日志与传统的消息传递相比

基于日志的方法天然支持fan-out，因为多个消费者可以独立读取日志，而不会相互影响。读取日志不会将其从日志中删除。为了在一组消费者之间实现负载均衡，代理可以将整个分区分配给消费者组中的某个节点，而不是将单条消息分配给消费者客户端。



1. topic1

1. 1. group1：

1. 1. 1. user 1

1. 1. 1. 1. node 1
         2. node 2

1. 1. 1. user 2

1. 1. group2

1. 1. 1. user 1
      2. user 2



然后每个客户端将消费被指派分区中的所有消息。通常情况下，当一个用户被指派了一个日志分区时，它会以简单的单线程方式顺序地读取分区中的消息。这种粗粒度的负载均衡方法有一些缺点：

1. 共享消费主题工作的节点数，最多为该主题中的日志分区数，因为同一个分区内的所有消息被传送到同一节点
2. 如果某条消息处理缓慢，则它会阻塞该分区中后续消息的处理

因此在消息处理代价高昂，希望逐条并行处理，以及消息的顺序没那么重要的情况下，JMS/AMQP的风格的消息代理是可取的，另一方面，在消息吞吐量很高，处理迅速、顺序很重要的情况下，基于日志的方法表现的很好。
