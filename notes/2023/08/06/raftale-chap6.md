partitions， also known sharding
## 分区是什么？
复制：在不同的节点有相同的数据；
分区：逻辑上放在一张表的数据实际上在物理层面分布在多个节点

## 为什么要分区呢？
主要还是为了scalability可伸缩性：
我们以一张表来说，如果没有分区，所有的查询必然落在这个表所在的物理节点上，但如果这张表有分区，并对查询进行了路由，那么查询会落在单个分区上，每个节点可以独立执行，还可以通过添加更多的节点来扩大查询的吞吐量。

## 如何进行分区
同一张表的数据进行分区，必然要有分区策略来决定哪些数据到哪些节点上。

分区策略：
1. 随机分配：查询一个特定的值时不知道它在哪个分区，必须并行的查询所有的节点
2. 基于key的hash分区：

1. 1. 分区如果要遵循某种模式，那分区时必然要有一个key来做路由，它可以是主键
2. 对每个分区分配一个hash范围，然后对key做hash运算，就能知道每个key会落在哪个分区。
3. 看起来是似乎是随机分配的，但实际上解决了随机分配的缺点：即对特定key的查询不知道这个key在哪个分区
4. 不幸的是，范围查询必须查询所有的分区

1. 基于key的范围分区：

1. 1. 为每个分区指定一个连续的key范围，可以保证范围查询，如果key的分布是均匀的，那分区必然也是均匀的；
2. 但在某些特定的查询模式下可能会导致热点问题，如果key是时间戳，那近期的所有查询都可能在某一个分区。一种解决思路是 时间戳 + 其他key分区，但也意味着查询要带上这个key

### Skewed workloads and relieving hot spots
哈希分区可以帮助减少hot spot，但很难完全避免。极端情况，所有的读写操作都是针对于同一个键，所有的请求都会被路由到同一个分区。
试想，一个拥有百万follower到up主发布了一个帖子，接下来会有百万级别的点赞和评论都针对于这一个帖子的key，这些写入将导向同一个分区。
遗憾的是，数据库是无法自动解决这种skew的，更多的还是要从应用程序入手，比如一个主键被认为是极其火爆的，那就可以给这个key的结尾加上一个随机数来写入不同的100分区。但查询又必须查询这100个分区进行数据的合并，所以这个取舍要根据具体系统来。

### 二级索引
如果分区，二级索引该如何查询。
关系型数据库中，二级索引就是非主键索引；文档型数据库中，如ES，二级索引就是倒排索引。

### 本地索引
每个分区独立的维护各自的耳机索引，这个耳机索引只包含了这个分区对应的记录。这种基于文档区分的索引也被称为本地索引。

读操作的时候需要读取所有分区，将爱过你所有分区的返回结果进行合并。

### 全局索引
相比于本地索引在本分区构建，全局的二级索引包含了所有分区的数据，优势就是读操作时能够很快的知道在哪个分区，不需要扫描所有分区。但缺点是，由于要维护一个全局的索引，所以每个分区的写入都需要构建这个全局索引（还涉及到跨分区的事务保证），写操作会变慢变复杂。
