##### Partitioned hash joins
如果 Map 侧连接的输入以相同的方式进行分区，则散列连接方法可以独立应用于每个分区。

如果分区无误，所有你可能需要连接的记录都落在同一个编号的分区中。因此每个 Mapper 只需要从输入两端各读取一个分区就足够了。好处是每个 Mapper 都可以在内存散列表中少放点数据。

局限性：这种方法只有当连接两端输入有相同的分区数，且两侧的记录都是使用相同的键与相同的哈希函数做分区时才适用。如果输入是由之前执行过这种分组的 MapReduce 作业生成的，那么这可能是一个合理的假设。

分区散列连接在 Hive 中称为 **Map 侧桶连接（bucketed map joins）**

##### Map-side merge joins
如果输入数据集不仅以相同的方式进行分区，而且还基于相同的键进行 **排序**，这种情况下，这时候 Mapper 可以执行归并操作（通常由 Reducer 执行）的归并操作：按键递增的顺序依次读取两个输入文件，将具有相同键的记录配对。

如果能进行 Map 侧合并连接，这通常意味着前一个 MapReduce 作业可能一开始就已经把输入数据做了分区并进行了排序。原则上这个连接就可以在前一个作业的 Reduce 阶段进行。但使用独立的仅 Map 作业有时也是合适的，例如，分好区且排好序的中间数据集可能还会用于其他目的。

##### MapReduce workflows with map-side joins
当下游作业使用 MapReduce 连接的输出时，选择 Map 侧连接或 Reduce 侧连接会影响输出的结构。
* Reduce 侧连接的输出是按照 **连接键** 进行分区和排序的。
* Map 端连接的输出则按照与较大输入相同的方式进行分区和排序（因为无论是使用分区连接还是广播连接，连接较大输入端的每个文件块都会启动一个 Map 任务）。

Map 侧连接依赖于对输入数据集的大小，有序性和分区方式的假设。在优化连接策略时，分布式文件系统中数据集的物理布局非常重要：仅仅知道编码格式和数据存储目录的名称是不够的；还必须知道数据是按哪些键做的分区和排序，以及分区的数量。

在 Hadoop 生态系统中，这种关于数据集分区的元数据通常在 HCatalog 和 Hive Metastore 中维护。